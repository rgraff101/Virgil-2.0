## Kajsa Pruner

### This week

- Started taking pictures of the buckets so that we can start creating our own trained model for the AI kit and camera. We have started with labeling 100 pictures and 50 for verification.
- Doing research on the training model that we have to create. There are a couple tutorials out there but not many but working on getting this set up.
- Started incorporating the AI camera to our code. Also worked on using the code we have working right now (for the RPLidar and motors) to work for the plan that we had with the different stages. Just so we have a structure of everything, we havent tested any of the new code yet since we are just trying to incorporate the camera as well first.

### Next week

- get the AI camera to work and figure out what output this gives us so that we can start using that output to read where we are in the maze etc.
- Get our model training with the pictures to work. It was reccomended to have 200-500 pictures so we might have to take more pictures next week depending on how the model is working
- start attaching all the parts to virgil 3.0

> ### Advisor's Comments
> Thank you for the updates. Please see my thoughts below.
> 1. I've seen 102 pictures in your annotation job. And you need to split the verification pictures out. I also suggest you use fewer numbers for verification, may be 20 or 30?
> 2. Please briefly summarize the research you've done.
> 3. Please briefly state how you are going to incorporate the AI camera.
> 4. Please do not include the work you are intending to help in the furue.

## Reagan Graff

### This week

- Made significant progress on the logic code, successfully creating a class with multiple functions and implementing stage progression based on specific tasks and conditions.
- Connected the Raspberry Pi AI camera; replaced a faulty cable.
- Cloned the hailo-rpi5 GitHub repository and experimented with its example programs.
- Modified the detection.py script to output detected objects both in the terminal and a text file.

### Next Week

- Develop a program to process camera output and send commands to the Raspberry Pi Picoâ€”for example, triggering specific actions when a person is detected. Implement parallel processing for the camera and motor logic.
- Transfer components to the new base.
- Continue refining the program to ensure smooth progression through all stages.
- Conduct testing to verify that the program correctly loops through each stage.

> ### Advisor's Comments
> Thank you for the updates. Please see my thoughts below.
> 1. Looking forward to testing the code. 
> 2. Not sure about the `detection.py` since I cannot see your code.
> 3. Plan looks great, but also intense.

## Ethan Durham

### This Week

- Kajsa and I started taking images of buckets so that we could train a new yoloV8 model.
- Created two sets of data from the images: Training and Test. Training has 102 images, and Test has 40 images.
- Manually converted the images from HEIC files to jpg for labeling software to work.
- I tried to use LabelImg to annotate the images, but that did not work with my machine. So, I switched to the web-based Roboflow. <https://app.roboflow.com/liverpoolrc/annotate-buckets/annotate>
- Added three files to Documents Directory that provide links/steps on how to train a new yoloV8 model using a custom dataset

### Next Week

- Have the testing data set completely labeled.
- Start the process of training the new yoloV8 model
- Switch the components from Virgil to the new base.

> ### Advisor's Comments
> Thank you for the updates. 
> - My only concern is your time is getting tight.


## LZ

To play with [person_dection.py](Code/person_dection.py)

1. Install the Basic Pipelines for AI kit.

```console
cd ~
git clone https://github.com/hailo-ai/hailo-rpi5-examples.git
cd hailo-rpi5-examples
./install.sh
```

Or, follow installation [instructions](https://github.com/hailo-ai/hailo-rpi5-examples?tab=readme-ov-file#installation).

2. Setup a dedicated virtual env

```console
cd ~/hailo-rpi5-examples/
./setup_env.sh
```

3. Run modified script

```console
python ~/Virgil-2.0/Code/person_detection.py --input rpi
```

> I've cloned `Virgil-2.0` to my home directory, so I'll just run above command.
You'll need to change the path to [person_dection.py](Code/person_dection.py) based on where you save this script on your local machine.
