## Kajsa Pruner
### This week:
- Started taking pictures of the buckets so that we can start creating our own trained model for the AI kit and camera. We have started with labeling 100 pictures and 50 for verification.
- Doing research on the training model that we have to create. There are a couple tutorials out there but not many but working on getting this set up.
- Started incorporating the AI camera to our code. Also worked on using the code we have working right now (for the RPLidar and motors) to work for the plan that we had with the different stages. Just so we have a structure of everything, we havent tested any of the new code yet since we are just trying to incorporate the camera as well first.
### Next week:
- get the AI camera to work and figure out what output this gives us so that we can start using that output to read where we are in the maze etc.
- Get our model training with the pictures to work. It was reccomended to have 200-500 pictures so we might have to take more pictures next week depending on how the model is working
- start attaching all the parts to virgil 3.0? If Ethan needs help with this 

## Reagan Graff
### This week:
- Made significant progress on the logic code, successfully creating a class with multiple functions and implementing stage progression based on specific tasks and conditions.
- Connected the Raspberry Pi AI camera; replaced a faulty cable.
- Cloned the hailo-rpi5 GitHub repository and experimented with its example programs.
- Modified the detection.py script to output detected objects both in the terminal and a text file.
### Next Week:
- Develop a program to process camera output and send commands to the Raspberry Pi Picoâ€”for example, triggering specific actions when a person is detected. Implement parallel processing for the camera and motor logic.
- Transfer components to the new base.
- Continue refining the program to ensure smooth progression through all stages.
- Conduct testing to verify that the program correctly loops through each stage.

## Ethan Durham
### This Week:
- Kajsa and I started taking images of buckets so that we could train a new yoloV8 model.
- Created two sets of data from the images: Training and Test. Training has 102 images, and Test has 40 images.
- Manually converted the images from HEIC files to jpg for labeling software to work.
- I tried to use LabelImg to annotate the images, but that did not work with my machine. So, I switched to the web-based Roboflow. https://app.roboflow.com/liverpoolrc/annotate-buckets/annotate
### Next Week:
- Have the testing data set completely labeled.
- Start the process of training the new yoloV8 model
- Switch the components from Virgil to the new base. 
